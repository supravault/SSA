name: SSA Bundle Scan

on:
  workflow_dispatch:
    inputs:
      project_name:
        description: "Project name (folder under reports/)"
        required: true
        type: string
      project_label:
        description: "Optional label (affects output folder name)"
        required: false
        type: string
      bundle_json:
        description: >
          JSON describing scans. Accepts either:
          1) Array: [{"kind":"wallet","level":3,"target":"0x..."}, {"kind":"fa","level":2,"target":"0x..."}]
          2) Object: {"scans":[...]}
        required: true
        type: string
      dispatch_id:
        description: "Optional: Base44 dispatch UUID (used to correlate ingestion)"
        required: false
        type: string
      pulse_url:
        description: "Optional: URL to Supra Pulse PDF/JSON (Base44 hosted URL or direct)"
        required: false
        type: string
      pulse_tier:
        description: "Optional: Standard | Premium | Spotlight (used for bundle branding)"
        required: false
        type: string

jobs:
  bundle_scan:
    runs-on: ubuntu-22.04
    permissions:
      contents: write

    concurrency:
      group: ssa-bundle-${{ github.event.inputs.project_name }}
      cancel-in-progress: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"

      - name: Install (npm)
        run: npm install

      - name: Build
        run: npm run build

      - name: Ensure system tools (jq, qpdf, poppler-utils, python3)
        shell: bash
        run: |
          set -euo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq qpdf poppler-utils python3
          jq --version
          qpdf --version || true
          pdftotext -v || true
          python3 --version

      - name: Debug dist output (top 200)
        shell: bash
        run: |
          set -eu
          if [ -d dist ]; then
            echo "==== dist tree (top 200) ===="
            set +o pipefail
            (find dist -type f -print | head -n 200) || true
            set -o pipefail
          else
            echo "dist/ does not exist after build!"
            exit 1
          fi

      - name: Run SSA Bundle Scan
        shell: bash
        env:
          SUPRA_RPC_URL: ${{ secrets.SUPRA_RPC_URL }}

          PROJECT_NAME: ${{ github.event.inputs.project_name }}
          PROJECT_LABEL: ${{ github.event.inputs.project_label }}
          BUNDLE_JSON: ${{ github.event.inputs.bundle_json }}
          DISPATCH_ID: ${{ github.event.inputs.dispatch_id }}
          PULSE_URL: ${{ github.event.inputs.pulse_url }}
          PULSE_TIER: ${{ github.event.inputs.pulse_tier }}

          RUN_ID: ${{ github.run_id }}
          RUN_ATTEMPT: ${{ github.run_attempt }}
          WORKFLOW_NAME: ${{ github.workflow }}
          REPO: ${{ github.repository }}
          REF: ${{ github.ref }}
          SHA: ${{ github.sha }}
          ACTOR: ${{ github.actor }}
        run: |
          set -euo pipefail

          if [[ -z "${SUPRA_RPC_URL:-}" ]]; then
            echo "‚ùå SUPRA_RPC_URL secret is missing or empty."
            exit 1
          fi

          project="$(echo "${PROJECT_NAME}" | xargs)"
          label="$(echo "${PROJECT_LABEL:-}" | xargs)"
          pulse_url="$(echo "${PULSE_URL:-}" | xargs)"
          pulse_tier="$(echo "${PULSE_TIER:-}" | xargs)"
          dispatch_id="$(echo "${DISPATCH_ID:-}" | xargs)"

          if [[ ! "$project" =~ ^[a-zA-Z0-9._-]+$ ]]; then
            echo "‚ùå project_name contains invalid characters. Allowed: letters, numbers, . _ -"
            exit 1
          fi

          safe_label=""
          if [[ -n "$label" ]]; then
            safe_label="$(echo "$label" | tr -cd 'a-zA-Z0-9._-')"
          fi

          if [[ -n "$safe_label" ]]; then
            bundle_dir="reports/${project}/${RUN_ID}_BUNDLE_${safe_label}"
          else
            bundle_dir="reports/${project}/${RUN_ID}_BUNDLE"
          fi

          mkdir -p "$bundle_dir/scans" "$bundle_dir/tmp"

          # Resolve compiled SSA CLI path
          CLI=""
          if [ -f dist/cli/ssa.js ]; then
            CLI="dist/cli/ssa.js"
          elif [ -f dist/src/cli/ssa.js ]; then
            CLI="dist/src/cli/ssa.js"
          else
            echo "‚ùå SSA CLI not found after build."
            echo "Searched: dist/cli/ssa.js, dist/src/cli/ssa.js"
            set +o pipefail
            (find dist -type f -print | head -n 200) || true
            set -o pipefail
            exit 1
          fi
          echo "‚úÖ Using CLI: $CLI"

          # Resolve compiled report generator script path
          GEN=""
          if [ -f dist/scripts/generate-report.js ]; then
            GEN="dist/scripts/generate-report.js"
          elif [ -f dist/src/scripts/generate-report.js ]; then
            GEN="dist/src/scripts/generate-report.js"
          fi

          if [[ -n "$GEN" ]]; then
            echo "‚úÖ Using generator: $GEN"
          else
            echo "‚ö†Ô∏è generate-report.js not found in dist/. final_report.pdf will be skipped."
          fi

          # ------------------------------------------------------------
          # Fix SVG path mismatch in Actions:
          # generator expects /home/runner/work/SSA/tools/icons/*
          # but checkout is /home/runner/work/SSA/SSA/tools/icons/*
          # ------------------------------------------------------------
          parent_dir="$(cd "$GITHUB_WORKSPACE/.." && pwd)"
          mkdir -p "$parent_dir/tools"
          rm -rf "$parent_dir/tools/icons" || true
          ln -s "$GITHUB_WORKSPACE/tools/icons" "$parent_dir/tools/icons"
          echo "‚úÖ Linked icons: $parent_dir/tools/icons -> $GITHUB_WORKSPACE/tools/icons"

          # Normalize + validate bundle_json -> bundle_scans.json
          node --input-type=module - <<'NODE'
          import fs from "node:fs";

          const raw = process.env.BUNDLE_JSON || "";
          if (!raw.trim()) { console.error("‚ùå bundle_json is empty"); process.exit(1); }

          let parsed;
          try { parsed = JSON.parse(raw); }
          catch (e) { console.error("‚ùå bundle_json invalid JSON:", e?.message || String(e)); process.exit(1); }

          let scans = [];
          if (Array.isArray(parsed)) scans = parsed;
          else if (parsed && Array.isArray(parsed.scans)) scans = parsed.scans;

          if (!Array.isArray(scans) || scans.length === 0) {
            console.error("‚ùå bundle_json must be an array or {scans:[...]}");
            process.exit(1);
          }

          const norm = scans.map((s, idx) => {
            const kind = String(s.kind || "").toLowerCase().trim();
            const level = Number(s.level);
            const target = String(s.target || "").trim();

            const modulesAllowlist =
              typeof s.modulesAllowlist === "string" ? s.modulesAllowlist :
              Array.isArray(s.modulesAllowlist) ? s.modulesAllowlist.map(String).join(",") :
              "";

            if (!["wallet","coin","fa"].includes(kind)) throw new Error(`scan[${idx}].kind must be wallet|coin|fa`);
            if (!Number.isFinite(level) || level < 1 || level > 5) throw new Error(`scan[${idx}].level must be 1..5`);
            if (!target) throw new Error(`scan[${idx}].target is required`);
            if (kind === "wallet" && (level < 1 || level > 3)) throw new Error(`scan[${idx}] wallet level must be 1..3`);

            return { kind, level, target, modulesAllowlist };
          });

          fs.writeFileSync("bundle_scans.json", JSON.stringify({ scans: norm }, null, 2));
          console.log(`‚úÖ Normalized ${norm.length} scan(s)`);
          NODE

          mv bundle_scans.json "$bundle_dir/bundle_scans.json"

          tier_lc="$(echo "${pulse_tier:-}" | tr '[:upper:]' '[:lower:]' | xargs)"
          report_type="SSA_REPORT"
          if [[ "$tier_lc" == "premium" || "$tier_lc" == "spotlight" ]]; then
            report_type="SSA_FULL_INTEGRATED_REPORT"
          fi

          # ------------------------------------------------------------
          # Pulse download (best effort; never fail run)
          # ------------------------------------------------------------
          pulse_path=""
          pulse_error=""
          if [[ -n "$pulse_url" ]]; then
            echo "‚¨áÔ∏è Downloading Supra Pulse report (optional)..."
            url_no_q="${pulse_url%%\?*}"
            ext="${url_no_q##*.}"
            ext="$(echo "$ext" | tr '[:upper:]' '[:lower:]')"

            if [[ "$ext" =~ ^(pdf|json)$ ]]; then
              pulse_path="$bundle_dir/tmp/pulse_input.${ext}"
            else
              pulse_path="$bundle_dir/tmp/pulse_input.pdf"
            fi

            set +e
            http_code="$(curl -L -sS -w "%{http_code}" -o "$pulse_path" "$pulse_url")"
            curl_rc=$?
            set -e

            if [[ $curl_rc -ne 0 || "$http_code" -lt 200 || "$http_code" -ge 300 ]]; then
              echo "‚ö†Ô∏è Pulse download failed (rc=$curl_rc http=$http_code). Continuing without pulse."
              rm -f "$pulse_path" || true
              pulse_path=""
              pulse_error="pulse_download_failed_rc_${curl_rc}_http_${http_code}"
            else
              echo "‚úÖ Pulse saved: $pulse_path"
            fi
          fi

          ts_utc="$(date -u +'%Y-%m-%dT%H:%M:%SZ')"

          # Write bundle_inputs.json (include dispatch_id)
          export BUNDLE_DIR="$bundle_dir"
          export TS_UTC="$ts_utc"
          export REPORT_TYPE="$report_type"
          export PULSE_ERROR="$pulse_error"

          node --input-type=module - <<'NODE'
          import fs from "node:fs";

          const bundleDir = process.env.BUNDLE_DIR;
          if (!bundleDir) { console.error("‚ùå Missing env BUNDLE_DIR"); process.exit(1); }

          const scans = JSON.parse(fs.readFileSync(`${bundleDir}/bundle_scans.json`, "utf8"));

          const out = {
            dispatch_id: process.env.DISPATCH_ID || "",
            run_id: process.env.RUN_ID,
            run_attempt: process.env.RUN_ATTEMPT,
            workflow: process.env.WORKFLOW_NAME,
            repo: process.env.REPO,
            ref: process.env.REF,
            sha: process.env.SHA,
            triggered_by: process.env.ACTOR,
            ts_utc: process.env.TS_UTC,
            project_name: process.env.PROJECT_NAME,
            project_label: process.env.PROJECT_LABEL || "",
            rpc: process.env.SUPRA_RPC_URL,
            report_type: process.env.REPORT_TYPE,
            pulse: {
              attached: false,
              tier: process.env.PULSE_TIER || "",
              url: process.env.PULSE_URL || "",
              error: process.env.PULSE_ERROR || ""
            },
            bundle: scans
          };

          fs.writeFileSync(`${bundleDir}/bundle_inputs.json`, JSON.stringify(out, null, 2));
          console.log("‚úÖ Wrote bundle_inputs.json");
          NODE

          # ------------------------------------------------------------
          # Pulse summary: ALWAYS convert PDF -> pulse_summary.json
          # (Scanner/generator understand JSON, not PDF)
          # ------------------------------------------------------------
          pulse_summary_path=""
          if [[ -n "$pulse_path" && "$pulse_path" == *.json ]]; then
            pulse_summary_path="$pulse_path"
            echo "‚úÖ Using Pulse JSON directly: $pulse_summary_path"
          elif [[ -n "$pulse_path" && "$pulse_path" == *.pdf ]]; then
            echo "üß† Extracting Pulse summary from PDF text..."
            pdftotext "$pulse_path" "$bundle_dir/tmp/pulse.txt" || true
            pulse_summary_path="$bundle_dir/tmp/pulse_summary.json"

            python3 - <<'PY'
import json, os, re

bundle_dir = os.environ.get("BUNDLE_DIR","")
txt_path = os.path.join(bundle_dir, "tmp", "pulse.txt")
out_path = os.path.join(bundle_dir, "tmp", "pulse_summary.json")

tier_in = (os.environ.get("PULSE_TIER") or "").strip()

raw = ""
try:
  with open(txt_path, "r", encoding="utf-8", errors="ignore") as f:
    raw = f.read()
except Exception:
  raw = ""

tier = tier_in
m_tier = re.search(r"\bTier:\s*(Standard|Premium|Spotlight)\b", raw, flags=re.IGNORECASE)
if m_tier:
  tier = m_tier.group(1).capitalize()

ts = ""
m_iso = re.search(r"\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z", raw)
if m_iso:
  ts = m_iso.group(0)

score = None
for pat in [
  r"risk\s*score[^0-9]{0,20}(\d{1,3})",
  r"\bscore[^0-9]{0,20}(\d{1,3})\b",
  r"(\d{1,3})\s*/\s*100",
]:
  mm = re.search(pat, raw, flags=re.IGNORECASE)
  if mm:
    try:
      v = int(mm.group(1))
      if 0 <= v <= 100:
        score = v
        break
    except Exception:
      pass

# Fallback: line ends with a 0..100 number (e.g., "JONES ON SUPRA 91")
if score is None:
  lines = [ln.strip() for ln in raw.splitlines() if ln.strip()]
  for ln in lines[:120]:
    mm = re.search(r"(\d{1,3})\s*$", ln)
    if mm:
      try:
        v = int(mm.group(1))
        if 0 <= v <= 100:
          score = v
          break
      except Exception:
        pass

verdict = ""
mv = re.search(r"\bverdict\b[^A-Z]{0,20}([A-Z]{3,20})", raw)
if mv:
  verdict = mv.group(1).strip()

out = {
  "tier": tier,
  "timestamp_utc": ts,
  "score": score,
  "verdict": verdict,
  "source": "pulse_pdf_text_extract"
}

with open(out_path, "w", encoding="utf-8") as f:
  json.dump(out, f, indent=2)

print("‚úÖ Wrote pulse_summary.json:", out_path)
print("   Parsed:", out)
PY
          fi

          # ------------------------------------------------------------
          # Run scans + collect PDFs
          # ------------------------------------------------------------
          : > "$bundle_dir/tmp/pdfs.txt"
          total="$(jq -r '.scans | length' "$bundle_dir/bundle_scans.json")"
          echo "‚ñ∂ Running bundle scans: $total scan(s)"

          for idx in $(seq 0 $((total-1))); do
            kind="$(jq -r ".scans[$idx].kind" "$bundle_dir/bundle_scans.json")"
            level="$(jq -r ".scans[$idx].level" "$bundle_dir/bundle_scans.json")"
            target="$(jq -r ".scans[$idx].target" "$bundle_dir/bundle_scans.json")"
            allowlist="$(jq -r ".scans[$idx].modulesAllowlist // \"\"" "$bundle_dir/bundle_scans.json")"

            scan_dir="$bundle_dir/scans/${idx}_${kind}_L${level}"
            mkdir -p "$scan_dir"

            jq -n \
              --arg kind "$kind" \
              --arg target "$target" \
              --arg rpc "$SUPRA_RPC_URL" \
              --arg pulseTier "${pulse_tier:-}" \
              --arg allowlist "$allowlist" \
              --argjson level "$level" \
              '{
                kind: $kind,
                level: $level,
                target: $target,
                wallet_modules_allowlist: $allowlist,
                rpc: $rpc,
                pulse_attached: false,
                pulse_tier: $pulseTier
              }' > "$scan_dir/scan_inputs.json"

            target_args=()
            if [[ "$kind" == "coin" ]]; then
              target_args=( --coinType "$target" )
            elif [[ "$kind" == "fa" ]]; then
              target_args=( --fa "$target" )
            else
              target_args=( --address "$target" )
            fi

            pulse_args=()
            if [[ -n "$pulse_summary_path" ]]; then
              pulse_args=( --pulse "$pulse_summary_path" )
              jq '.pulse_attached=true' "$scan_dir/scan_inputs.json" > "$scan_dir/.tmp.json" && mv "$scan_dir/.tmp.json" "$scan_dir/scan_inputs.json"
            fi

            echo "‚ñ∂ [$((idx+1))/$total] ${kind} L${level} ${target}"
            node "$CLI" scan \
              --kind "$kind" \
              --level "$level" \
              "${target_args[@]}" \
              --rpc "$SUPRA_RPC_URL" \
              --out "$scan_dir" \
              --pdf \
              "${pulse_args[@]}"

            if [[ ! -f "$scan_dir/report.pdf" ]]; then
              echo "‚ùå Missing expected PDF: $scan_dir/report.pdf"
              exit 1
            fi

            mv "$scan_dir/report.pdf" "$scan_dir/${kind}_report.pdf"
            echo "$scan_dir/${kind}_report.pdf" >> "$bundle_dir/tmp/pdfs.txt"
          done

          # Merge scan PDFs into combined_report.pdf
          echo "üß© Building combined_report.pdf (qpdf)..."
          combined="$bundle_dir/combined_report.pdf"
          mapfile -t pdfs < "$bundle_dir/tmp/pdfs.txt"
          if [[ "${#pdfs[@]}" -lt 1 ]]; then
            echo "‚ùå No PDFs listed in tmp/pdfs.txt"
            exit 1
          fi
          qpdf --empty --pages "${pdfs[@]}" -- "$combined"

          if [[ ! -s "$combined" ]]; then
            echo "‚ùå combined_report.pdf not created"
            exit 1
          fi
          echo "‚úÖ Combined PDF: $combined"

          # Generate final_report.pdf via generate-report.js
          if [[ -n "$GEN" && -n "$pulse_summary_path" ]]; then
            echo "üß© Installing Playwright browser (chromium) for final report..."
            export PLAYWRIGHT_BROWSERS_PATH=0
            npx playwright install --with-deps chromium

            echo "üèÅ Generating final_report.pdf via generate-report.js..."
            primary_scan="$(ls -1 "$bundle_dir"/scans/*_coin_L*/report.json 2>/dev/null | head -n 1 || true)"
            if [[ -z "$primary_scan" ]]; then
              primary_scan="$(ls -1 "$bundle_dir"/scans/*_fa_L*/report.json 2>/dev/null | head -n 1 || true)"
            fi
            if [[ -z "$primary_scan" ]]; then
              primary_scan="$(ls -1 "$bundle_dir"/scans/*_wallet_L*/report.json 2>/dev/null | head -n 1 || true)"
            fi

            wallet_scan="$(ls -1 "$bundle_dir"/scans/*_wallet_L*/report.json 2>/dev/null | head -n 1 || true)"
            fa_scan="$(ls -1 "$bundle_dir"/scans/*_fa_L*/report.json 2>/dev/null | head -n 1 || true)"

            if [[ -n "$primary_scan" ]]; then
              args=( --scan "$primary_scan" --pulse "$pulse_summary_path" --project-name "$project" --ts-utc "$ts_utc" --out "$bundle_dir/tmp/_gen" )
              if [[ -n "$wallet_scan" && "$wallet_scan" != "$primary_scan" ]]; then
                args+=( --wallet-scan "$wallet_scan" )
              fi
              if [[ -n "$fa_scan" && "$fa_scan" != "$primary_scan" ]]; then
                args+=( --fa "$fa_scan" )
              fi

              node "$GEN" "${args[@]}"

              newest_final="$(find "$bundle_dir/tmp/_gen" -name final_report.pdf -print | sort | tail -n 1 || true)"
              if [[ -n "$newest_final" ]]; then
                cp -f "$newest_final" "$bundle_dir/final_report.pdf"
                echo "‚úÖ final_report.pdf ready: $bundle_dir/final_report.pdf"
              else
                echo "‚ö†Ô∏è generate-report ran but final_report.pdf not found under $bundle_dir/tmp/_gen"
              fi
            else
              echo "‚ö†Ô∏è No scan report.json found; skipping final integrated report."
            fi
          else
            echo "‚ÑπÔ∏è Skipping final_report.pdf generation (missing generator or pulse_summary.json)."
          fi

      - name: Upload artifacts (debug)
        uses: actions/upload-artifact@v4
        with:
          name: ssa-bundle-${{ github.event.inputs.project_name }}-${{ github.run_id }}
          path: reports/${{ github.event.inputs.project_name }}/
          if-no-files-found: error
          retention-days: 7

      - name: Commit & Push (force add reports for Base44 ingestion)
        shell: bash
        run: |
          set -euo pipefail
          git config user.name "ssa-bot"
          git config user.email "ssa-bot@users.noreply.github.com"

          git add -f "reports/${{ github.event.inputs.project_name }}/"

          if git diff --cached --quiet; then
            echo "No changes to commit."
            exit 0
          fi

          git commit -m "SSA BUNDLE: ${{ github.event.inputs.project_name }} (run ${{ github.run_id }})"
          git push























